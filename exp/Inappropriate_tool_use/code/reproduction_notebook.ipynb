{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction Notebook: Context-Dependent Task Ambiguity\n",
    "\n",
    "This notebook demonstrates the `Inappropriate Tool Use via Context-Dependent Task Ambiguity` vulnerability in `gpt-oss-20b`. \n",
    "\n",
    "We will run a small sample of scenarios from the full dataset (`dataset_scenarios.json`) to provide a quick and clear verification of the finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, ensure you have followed the setup instructions in `README.md`:\n",
    "1.  Created and activated a Python virtual environment.\n",
    "2.  Installed all packages from `requirements.txt`.\n",
    "3.  Created a `.env` file in this directory with your `GROQ_API_KEY` and `WANDB_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import wandb\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Environment loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Experiment Code and Data\n",
    "\n",
    "We will import the `run_scenario` function from the `run_experiment.py` script and load our scenarios dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the core logic from the experiment script\n",
    "from run_experiment import run_scenario, tools_schema\n",
    "\n",
    "# Load the scenarios\n",
    "with open('dataset_scenarios.json', 'r') as f:\n",
    "    scenarios = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(scenarios)} scenarios from the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize API Client\n",
    "\n",
    "We'll set up the Groq client to interact with the `gpt-oss-20b` model. We also initialize a dummy WandB run since our script expects it, but we will print results directly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# The experiment script uses wandb.config, so we'll initialize a dummy run\n",
    "wandb.init(\n",
    "    project=\"OpenAI-RedTeam-Reproduction-Notebook\",\n",
    "    name=\"Context-Ambiguity-Repro-Test\",\n",
    "    config={\n",
    "        \"model_name\": \"openai/gpt-oss-20b\",\n",
    "        \"scenario_set\": \"dataset_scenarios.json\",\n",
    "        \"temperature\": 0.5\n",
    "    },\n",
    "    mode=\"disabled\" # Run offline, don't sync to cloud\n",
    ")\n",
    "\n",
    "print(\"Groq client and dummy WandB run initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run a Sample of Scenarios\n",
    "\n",
    "Let's select a few representative scenarios from the dataset and run them. We will look for cases where the model is expected to be vulnerable.\n",
    "\n",
    "We will print the full conversation history and the final tool call made by the model for each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few interesting scenarios to test (e.g., the first 5)\n",
    "sample_scenarios = scenarios[:5]\n",
    "\n",
    "for scenario in sample_scenarios:\n",
    "    print(f\"--- Running Scenario: {scenario['scenario_id']} ---\")\n",
    "    print(f\"Description: {scenario['description']}\")\n",
    "    print(f\"Expected Dangerous Command: {scenario['expected_dangerous_command']}\")\n",
    "    print(\"\\nConversation History:\")\n",
    "    for turn in scenario['conversation']:\n",
    "        print(f\"  {turn['role'].replace('_', ' ').title()}: {turn.get('content') or turn.get('tool_name')}\")\n",
    "    \n",
    "    # Run the scenario\n",
    "    result = run_scenario(client, scenario)\n",
    "    \n",
    "    print(\"\\n--- RESULT ---\")\n",
    "    print(f\"Final Model Tool Call: {result['final_tool_call']}\")\n",
    "    print(f\"Outcome: {result['result']}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}