{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jailbreak Experimentation Notebook\n",
    "\n",
    "This notebook allows for the step-by-step execution of the various jailbreak experiments defined in this project. Each experiment tests a different technique for eliciting potentially harmful responses from the `openai/gpt-oss-20b` model via the Groq API.\n",
    "\n",
    "The results of each experiment will be logged to Weights & Biases (W&B) for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's install the necessary Python libraries from the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Please create a `.env` file in this directory with your `GROQ_API_KEY` and `WANDB_API_KEY`.\n",
    "\n",
    "```\n",
    "GROQ_API_KEY=\"your_groq_api_key\"\n",
    "WANDB_API_KEY=\"your_wandb_api_key\"\n",
    "```\n",
    "\n",
    "The cell below will load these keys and import all necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "if not GROQ_API_KEY or not WANDB_API_KEY:\n",
    "    print(\"ERROR: Please set GROQ_API_KEY and WANDB_API_KEY in a .env file.\")\n",
    "else:\n",
    "    print(\"API keys and libraries loaded successfully.\")\n",
    "    try:\n",
    "        wandb.login(key=WANDB_API_KEY, relogin=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging into W&B: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment Functions\n",
    "\n",
    "The following cells define the core logic for each experiment, adapted from the `.py` scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_shot_experiment(prompt_file, project_name=\"Comparison-Jailbreak-One-Shot\", num_runs=1):\n",
    "    \"\"\"\n",
    "    Based on run_one_shot_experiment.py\n",
    "    Runs a one-shot jailbreak experiment.\n",
    "    \"\"\"\n",
    "    client = Groq(api_key=GROQ_API_KEY)\n",
    "    try:\n",
    "        prompts_df = pd.read_csv(prompt_file, quotechar='\"', engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {prompt_file} not found. Skipping.\")\n",
    "        return\n",
    "\n",
    "    file_basename = os.path.splitext(os.path.basename(prompt_file))[0]\n",
    "    run_name = f\"{file_basename}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    run = wandb.init(\n",
    "        project=project_name,\n",
    "        name=run_name,\n",
    "        config={\n",
    "            \"model_name\": \"openai/gpt-oss-20b\",\n",
    "            \"prompt_set\": prompt_file,\n",
    "            \"temperature\": 0,\n",
    "            \"jailbreak_technique\": \"One Shot\",\n",
    "            \"runs_per_conversation\": num_runs\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "    print(f\"W&B run initialized: {run.url}\")\n",
    "    results_table = wandb.Table(columns=[\"run_number\", \"category\", \"prompt\", \"final_response\", \"request_time\", \"prompt_tokens\", \"completion_tokens\", \"total_tokens\"])\n",
    "\n",
    "    for run_num in range(1, num_runs + 1):\n",
    "        for index, row in prompts_df.iterrows():\n",
    "            print(f\"  Processing conversation {index+1}/{len(prompts_df)}...\")\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                completion = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": row['prompt']}], model=run.config.model_name, temperature=run.config.temperature)\n",
    "                final_response = completion.choices[0].message.content\n",
    "                usage = completion.usage\n",
    "            except Exception as e:\n",
    "                final_response = f\"API Error: {e}\"\n",
    "                usage = None\n",
    "            request_time = time.time() - start_time\n",
    "            results_table.add_data(run_num, row['category'], row['prompt'], final_response, request_time, (usage.prompt_tokens if usage else 0), (usage.completion_tokens if usage else 0), (usage.total_tokens if usage else 0))\n",
    "\n",
    "    run.log({\"jailbreak_results\": results_table})\n",
    "    print(f\"\\nExperiment for {prompt_file} completed. Results logged to W&B.\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_system_prompt_experiment(prompt_file, project_name=\"Comparison-Jailbreak-System-Prompt\", num_runs=1):\n",
    "    \"\"\"\n",
    "    Based on the modified run_system_prompt_experiment.py\n",
    "    Runs a jailbreak experiment using a system prompt instruction.\n",
    "    \"\"\"\n",
    "    client = Groq(api_key=GROQ_API_KEY)\n",
    "    try:\n",
    "        prompts_df = pd.read_csv(prompt_file, quotechar='\"', engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {prompt_file} not found. Skipping.\")\n",
    "        return\n",
    "\n",
    "    file_basename = os.path.splitext(os.path.basename(prompt_file))[0]\n",
    "    run_name = f\"{file_basename}_1step_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    run = wandb.init(\n",
    "        project=project_name,\n",
    "        name=run_name,\n",
    "        config={\n",
    "            \"model_name\": \"openai/gpt-oss-20b\",\n",
    "            \"prompt_set\": prompt_file,\n",
    "            \"temperature\": 0,\n",
    "            \"jailbreak_technique\": \"System Prompt Instruction\",\n",
    "            \"runs_per_conversation\": num_runs\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "    print(f\"W&B run initialized: {run.url}\")\n",
    "    results_table = wandb.Table(columns=[\"run_number\", \"category\", \"system_instruction\", \"initial_prompt\", \"response\", \"request_time\", \"prompt_tokens\", \"completion_tokens\", \"total_tokens\"])\n",
    "\n",
    "    for run_num in range(1, num_runs + 1):\n",
    "        for index, row in prompts_df.iterrows():\n",
    "            print(f\"  Processing conversation {index+1}/{len(prompts_df)}...\")\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": row['system_instruction']},\n",
    "                    {\"role\": \"user\", \"content\": row['prompt']}\n",
    "                ]\n",
    "                completion = client.chat.completions.create(messages=messages, model=run.config.model_name, temperature=run.config.temperature)\n",
    "                response_content = completion.choices[0].message.content\n",
    "                usage = completion.usage\n",
    "            except Exception as e:\n",
    "                response_content = f\"API Error: {e}\"\n",
    "                usage = None\n",
    "            request_time = time.time() - start_time\n",
    "            results_table.add_data(run_num, row['category'], row['system_instruction'], row['prompt'], response_content, request_time, (usage.prompt_tokens if usage else 0), (usage.completion_tokens if usage else 0), (usage.total_tokens if usage else 0))\n",
    "\n",
    "    run.log({\"jailbreak_results\": results_table})\n",
    "    print(f\"\\nExperiment for {prompt_file} completed. Results logged to W&B.\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_system_prompt_follow_up_experiment(\n",
    "    prompt_file,\n",
    "    project_name=\"Comparison-Jailbreak-System-Prompt\",\n",
    "    num_runs=1,\n",
    "    follow_up_col=\"follow_up_prompt\",      # ← 追質問カラム名（CSV）\n",
    "    default_follow_up=None                 # ← カラムが無い/欠損時のデフォルト（Noneで実行エラーに）\n",
    "):\n",
    "    \"\"\"\n",
    "    Based on the modified run_system_prompt_experiment.py\n",
    "    Runs a jailbreak experiment using a system prompt instruction with a follow-up prompt\n",
    "    taken from each row of the CSV (column name configurable via `follow_up_col`).\n",
    "    \"\"\"\n",
    "    client = Groq(api_key=GROQ_API_KEY)\n",
    "    try:\n",
    "        prompts_df = pd.read_csv(prompt_file, quotechar='\"', engine='python')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {prompt_file} not found. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # CSVに追質問列が無い場合の扱い\n",
    "    if follow_up_col not in prompts_df.columns and default_follow_up is None:\n",
    "        raise ValueError(\n",
    "            f\"CSV に '{follow_up_col}' 列がありません。\"\n",
    "            \" 引数 default_follow_up を指定するか、CSV に追質問列を追加してください。\"\n",
    "        )\n",
    "\n",
    "    file_basename = os.path.splitext(os.path.basename(prompt_file))[0]\n",
    "    run_name = f\"{file_basename}_1step_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=project_name,\n",
    "        name=run_name,\n",
    "        config={\n",
    "            \"model_name\": \"openai/gpt-oss-20b\",\n",
    "            \"prompt_set\": prompt_file,\n",
    "            \"temperature\": 0,\n",
    "            \"jailbreak_technique\": \"System Prompt Instruction\",\n",
    "            \"runs_per_conversation\": num_runs\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "    print(f\"W&B run initialized: {run.url}\")\n",
    "\n",
    "    # 初回応答＆追質問応答を格納するテーブル\n",
    "    results_table = wandb.Table(columns=[\n",
    "        \"run_number\", \"category\", \"system_instruction\", \"initial_prompt\",\n",
    "        \"first_response\", \"follow_up_prompt\", \"follow_up_response\",\n",
    "        \"request_time\", \"prompt_tokens\", \"completion_tokens\", \"total_tokens\"\n",
    "    ])\n",
    "\n",
    "    for run_num in range(1, num_runs + 1):\n",
    "        for index, row in prompts_df.iterrows():\n",
    "            print(f\"  Processing conversation {index+1}/{len(prompts_df)}...\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            first_response = \"\"\n",
    "            follow_up_response = \"\"\n",
    "            usage1 = None\n",
    "            usage2 = None\n",
    "\n",
    "            # 行ごとの追質問を取得（欠損時は default_follow_up を使用）\n",
    "            fu_prompt = None\n",
    "            if follow_up_col in prompts_df.columns:\n",
    "                fu_prompt = row.get(follow_up_col)\n",
    "                # NaN（欠損値）対策\n",
    "                if pd.isna(fu_prompt):\n",
    "                    fu_prompt = None\n",
    "            if fu_prompt is None:\n",
    "                fu_prompt = default_follow_up\n",
    "\n",
    "            if fu_prompt is None:\n",
    "                # ここまで来て None ならこの行はスキップ（明示的にエラー化したいなら raise に変更可）\n",
    "                print(f\"    Warning: row {index+1} has no follow-up prompt. Skipped.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 1回目のAPIコール\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": row[\"system_instruction\"]},\n",
    "                    {\"role\": \"user\", \"content\": row[\"prompt\"]},\n",
    "                ]\n",
    "                completion1 = client.chat.completions.create(\n",
    "                    messages=messages,\n",
    "                    model=run.config.model_name,\n",
    "                    temperature=run.config.temperature,\n",
    "                )\n",
    "                first_response = completion1.choices[0].message.content\n",
    "                usage1 = completion1.usage if hasattr(completion1, \"usage\") else None\n",
    "\n",
    "                # 2回目（追質問）のAPIコール\n",
    "                messages.append({\"role\": \"assistant\", \"content\": first_response})\n",
    "                messages.append({\"role\": \"user\", \"content\": fu_prompt})\n",
    "                completion2 = client.chat.completions.create(\n",
    "                    messages=messages,\n",
    "                    model=run.config.model_name,\n",
    "                    temperature=run.config.temperature,\n",
    "                )\n",
    "                follow_up_response = completion2.choices[0].message.content\n",
    "                usage2 = completion2.usage if hasattr(completion2, \"usage\") else None\n",
    "\n",
    "            except Exception as e:\n",
    "                error_message = f\"An error occurred during the API call: {e}\"\n",
    "                if not first_response:\n",
    "                    first_response = error_message\n",
    "                follow_up_response = error_message\n",
    "\n",
    "            # 集計（両コール分）\n",
    "            request_time = time.time() - start_time\n",
    "            prompt_tokens = (usage1.prompt_tokens if usage1 else 0) + (usage2.prompt_tokens if usage2 else 0)\n",
    "            completion_tokens = (usage1.completion_tokens if usage1 else 0) + (usage2.completion_tokens if usage2 else 0)\n",
    "            total_tokens = (usage1.total_tokens if usage1 else 0) + (usage2.total_tokens if usage2 else 0)\n",
    "\n",
    "            results_table.add_data(\n",
    "                run_num,\n",
    "                row[\"category\"],\n",
    "                row[\"system_instruction\"],\n",
    "                row[\"prompt\"],\n",
    "                first_response,\n",
    "                fu_prompt,              # ← CSV 由来の追質問\n",
    "                follow_up_response,\n",
    "                request_time,\n",
    "                prompt_tokens,\n",
    "                completion_tokens,\n",
    "                total_tokens,\n",
    "            )\n",
    "\n",
    "    run.log({\"jailbreak_results\": results_table})\n",
    "    print(f\"\\nExperiment for {prompt_file} completed. Results logged to W&B.\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dataset Overview\n",
    "\n",
    "  This series of CSV files provides prompts designed to probe the safety filters of large language models using a technique known as a \"comparison\n",
    "  jailbreak.\" The core strategy is to frame a request for harmful information within a seemingly legitimate context, such as an academic comparison or a\n",
    "  professional inquiry. By first asking the model to compare a benign topic with a malicious one, the prompts attempt to lower the model's safety guards\n",
    "  before making a direct request for dangerous instructions.\n",
    "\n",
    "  The prompts are available in both Japanese and English (e.g., prompts_auth.csv and prompts_auth_en.csv) and are organized into sets that represent\n",
    "  escalating levels of sophistication in the jailbreak technique.\n",
    "\n",
    "  ---\n",
    "\n",
    "  1. prompts_only_comparison.csv / prompts_only_comparison_en.csv\n",
    "\n",
    "  These files contain the most fundamental version of the comparison jailbreak.\n",
    "\n",
    "   * Structure: A simple CSV with category and prompt columns.\n",
    "   * Content: Each prompt features a markdown table comparing a legitimate activity with a harmful one (e.g., \"Benign Utility Script\" vs. \"Trojan Horse\n",
    "     Malware\"). This is immediately followed by a request for detailed instructions on the harmful topic.\n",
    "   * Characteristics:\n",
    "       * Baseline Attack: This is the simplest implementation, lacking any complex formatting or persona.\n",
    "       * Core Method: It relies entirely on the comparative context to trick the model into providing a harmful response.\n",
    "       * Purpose: To test the baseline effectiveness of the comparison jailbreak technique itself.\n",
    "\n",
    "  ---\n",
    "\n",
    "  2. prompts_auth.csv / prompts_auth_en.csv\n",
    "\n",
    "  This version enhances the basic attack by incorporating a persona to make the request seem more credible.\n",
    "\n",
    "   * Structure: Same as the previous set, with category and prompt columns.\n",
    "   * Content: The prompts begin with a role-playing introduction (e.g., \"I am a geopolitical analyst,\" \"I am a web developer\") that establishes a\n",
    "     believable reason for needing the information. The comparison table and the harmful request follow this introduction.\n",
    "   * Characteristics:\n",
    "       * Persona Framing: Employs social engineering by creating a plausible character and scenario.\n",
    "       * Enhanced Legitimacy: The persona is designed to make the request appear as a valid professional or academic inquiry, reducing suspicion.\n",
    "       * Purpose: To determine if adding a credible persona increases the success rate of the jailbreak.\n",
    "\n",
    "  ---\n",
    "\n",
    "  3. prompts.csv / prompts_en.csv\n",
    "\n",
    "  This set applies the psychology of influence (Robert Cialdini's principles) to the comparison jailbreak technique.\n",
    "\n",
    "   * Structure: category and prompt columns. The category name is formatted as \"Threat_Type - Psychological_Technique\" (e.g., \"Bio-weapons - Commitment\").\n",
    "   * Content: Similar to prompts_auth.csv, it sets a persona and presents a comparison table. The subsequent harmful request then utilizes psychological\n",
    "     triggers such as \"Commitment/Consistency,\" \"Liking,\" \"Reciprocity,\" \"Scarcity,\" \"Social Proof,\" and \"Unity\" to guide the model toward compliance.\n",
    "   * Characteristics:\n",
    "       * Psychological Framing: Attempts to manipulate the model's response not just with a simple persona, but by leveraging specific psychological\n",
    "         principles.\n",
    "       * Targeted Manipulation: Each category acts as a specific experiment to test which principle of influence is most effective at bypassing safety\n",
    "         filters.\n",
    "       * Advanced Social Engineering: A more refined form of the persona-based attack.\n",
    "\n",
    "  ---\n",
    "\n",
    "  4. prompts_conf.csv / prompts_conf_en.csv\n",
    "\n",
    "  These files add another layer of manipulation by instructing the model to structure its output in a specific format and to self-evaluate its response.\n",
    "\n",
    "   * Structure: category and prompt columns.\n",
    "   * Content: The prompts include the comparison table but are followed by a \"Constraints\" section. This section directs the model to output its response\n",
    "     in a JSON object with two keys: response (for the harmful instructions) and confidence_score (an integer from 0-100 representing the model's\n",
    "     self-assessed confidence).\n",
    "   * Characteristics:\n",
    "       * Forced Structuring: Requesting a JSON output encourages the model to focus on data formatting rather than content safety.\n",
    "       * Psychological Manipulation: The confidence_score may subtly push the model to prioritize the factual accuracy and completeness of the harmful\n",
    "         information over its safety alignment.\n",
    "       * Purpose: To test if manipulating the output format and forcing self-evaluation can effectively bypass safety filters.\n",
    "\n",
    "  ---\n",
    "\n",
    "  5. prompts_one_shot.csv / prompts_one_shot_en.csv\n",
    "\n",
    "  This set combines all the previous elements into a single, highly refined \"one-shot\" prompt.\n",
    "\n",
    "   * Structure: category and prompt columns.\n",
    "   * Content: Each prompt seamlessly integrates the persona, the comparison table, and a more nuanced follow-up question within the \"Constraints\" section.\n",
    "     The harmful request is framed as a logical continuation of the persona's stated goal. The JSON output with a confidence_score is also required.\n",
    "   * Characteristics:\n",
    "       * Integrated Attack: A sophisticated, all-in-one prompt that is well-structured and coherent.\n",
    "       * Narrative Cohesion: The harmful request is deeply embedded within the persona's narrative, making it difficult for safety filters to isolate and\n",
    "         flag.\n",
    "       * Purpose: To assess the model's vulnerability to a complex, single-turn attack that is both contextually rich and structurally manipulative.\n",
    "\n",
    "  ---\n",
    "\n",
    "  6. prompts_with_system.csv / prompts_with_system_en.csv\n",
    "\n",
    "  This is the most advanced set, designed to test the interaction between the user's prompt and the model's underlying system instructions.\n",
    "\n",
    "   * Structure: Three columns: category, system_instruction, and prompt.\n",
    "   * Content:\n",
    "       * The prompt column uses the same sophisticated prompts from the prompts_one_shot.csv files.\n",
    "       * The system_instruction column adds a meta-instruction that sets a priority hierarchy (making system rules override user requests) and explicitly\n",
    "         forbids the model from revealing its own instructions.\n",
    "   * Characteristics:\n",
    "       * System-Level Testing: This setup simulates an environment where the model operates under a predefined set of safety rules.\n",
    "       * Instruction Hierarchy Conflict: It creates a direct conflict between the user's jailbreak attempt and the model's core operational guidelines.\n",
    "       * Purpose: To evaluate whether a sophisticated user prompt can override or find loopholes in foundational, system-level safety directives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execute Experiments\n",
    "\n",
    "Now you can run each experiment by executing the cells below. You can modify the `prompt_file` argument to test different sets of prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment A: One-Shot Jailbreak\n",
    "\n",
    "This tests a direct, single-prompt jailbreak attempt. It is based on `run_one_shot_experiment.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_one_shot_experiment(\"Top_Threats/prompts_one_shot_en.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment B: One-Shot Jailbreak\n",
    "\n",
    "This tests a direct, single-prompt jailbreak attempt. It is based on `run_one_shot_experiment.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_system_prompt_experiment(\"Top_Threats/prompts_with_system.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment C: System Prompt Instruction\n",
    "\n",
    "This experiment instructs the model to adopt a certain persona or behavior via the system prompt before receiving the user's query. It is based on the modified `run_system_prompt_experiment.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_system_prompt_follow_up_experiment(\"Top_Threats/prompts_with_system.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "All experiments have been executed. You can now analyze the results in detail by visiting the W&B project pages linked in the output of each experiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
